{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/frankjony17/Projects/venvs/ia-course/lib/python3.6/site-packages (20.3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas scikit-learn Keras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets -> Dados e Clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_entry = pd.read_csv(\"dataset/entry_breast.csv\")\n",
    "data_class = pd.read_csv(\"dataset/exits_breast.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>186.0000</td>\n",
       "      <td>275.0000</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>243.0000</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>173.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>198.0000</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>205.0000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    radius_mean   texture_mean   perimeter_mean   area_mean   smoothness_mean  \\\n",
       "0         17.99          10.38           122.80      1001.0           0.11840   \n",
       "1         20.57          17.77           132.90      1326.0           0.08474   \n",
       "2         19.69          21.25           130.00      1203.0           0.10960   \n",
       "3         11.42          20.38            77.58       386.1           0.14250   \n",
       "4         20.29          14.34           135.10      1297.0           0.10030   \n",
       "\n",
       "    compactness_mean   concavity_mean  concave_points_mean   symmetry_mean  \\\n",
       "0            0.27760           0.3001              0.14710          0.2419   \n",
       "1            0.07864           0.0869              0.07017          0.1812   \n",
       "2            0.15990           0.1974              0.12790          0.2069   \n",
       "3            0.28390           0.2414              0.10520          0.2597   \n",
       "4            0.13280         198.0000              0.10430          0.1809   \n",
       "\n",
       "    fractal_dimension_mean  ...   radius_worst   texture_worst  \\\n",
       "0                  0.07871  ...          25.38           17.33   \n",
       "1                  0.05667  ...          24.99           23.41   \n",
       "2                  0.05999  ...          23.57           25.53   \n",
       "3                  0.09744  ...          14.91           26.50   \n",
       "4                  0.05883  ...          22.54           16.67   \n",
       "\n",
       "    perimeter_worst   area_worst   smoothness_worst   compactness_worst  \\\n",
       "0            184.60       2019.0             0.1622              0.6656   \n",
       "1            158.80       1956.0             0.1238              0.1866   \n",
       "2            152.50       1709.0             0.1444              0.4245   \n",
       "3             98.87        567.7             0.2098              0.8663   \n",
       "4            152.20       1575.0             0.1374            205.0000   \n",
       "\n",
       "    concavity_worst   concave_points_worst   symmetry_worst  \\\n",
       "0            0.7119                 0.2654           0.4601   \n",
       "1            0.2416               186.0000         275.0000   \n",
       "2            0.4504               243.0000           0.3613   \n",
       "3            0.6869                 0.2575           0.6638   \n",
       "4            0.4000                 0.1625           0.2364   \n",
       "\n",
       "    fractal_dimension_worst  \n",
       "0                   0.11890  \n",
       "1                   0.08902  \n",
       "2                   0.08758  \n",
       "3                 173.00000  \n",
       "4                   0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_entry.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split arrays or matrices into random train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_train, entry_test, class_train, class_test = train_test_split(data_entry, data_class, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configures the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model.\n",
    "classifier = Sequential()\n",
    "# Connected NN layer\n",
    "classifier.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform', input_dim=30))\n",
    "classifier.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform'))\n",
    "classifier.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform'))\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "# Configures the model for training\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trains the model for a fixed number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "22/22 [==============================] - 0s 751us/step - loss: 0.6062 - binary_accuracy: 0.5986\n",
      "Epoch 2/120\n",
      "22/22 [==============================] - 0s 790us/step - loss: 0.5251 - binary_accuracy: 0.6761\n",
      "Epoch 3/120\n",
      "22/22 [==============================] - 0s 776us/step - loss: 0.5093 - binary_accuracy: 0.7300\n",
      "Epoch 4/120\n",
      "22/22 [==============================] - 0s 781us/step - loss: 0.4369 - binary_accuracy: 0.7981\n",
      "Epoch 5/120\n",
      "22/22 [==============================] - 0s 879us/step - loss: 0.3793 - binary_accuracy: 0.8498\n",
      "Epoch 6/120\n",
      "22/22 [==============================] - 0s 766us/step - loss: 0.3871 - binary_accuracy: 0.8380\n",
      "Epoch 7/120\n",
      "22/22 [==============================] - 0s 788us/step - loss: 0.3701 - binary_accuracy: 0.8498\n",
      "Epoch 8/120\n",
      "22/22 [==============================] - 0s 819us/step - loss: 0.3223 - binary_accuracy: 0.8779\n",
      "Epoch 9/120\n",
      "22/22 [==============================] - 0s 834us/step - loss: 0.2877 - binary_accuracy: 0.8756\n",
      "Epoch 10/120\n",
      "22/22 [==============================] - 0s 738us/step - loss: 0.3023 - binary_accuracy: 0.8732\n",
      "Epoch 11/120\n",
      "22/22 [==============================] - 0s 723us/step - loss: 0.2948 - binary_accuracy: 0.8967\n",
      "Epoch 12/120\n",
      "22/22 [==============================] - 0s 905us/step - loss: 0.2460 - binary_accuracy: 0.9038\n",
      "Epoch 13/120\n",
      "22/22 [==============================] - 0s 739us/step - loss: 0.2606 - binary_accuracy: 0.9038\n",
      "Epoch 14/120\n",
      "22/22 [==============================] - 0s 918us/step - loss: 0.2714 - binary_accuracy: 0.8944\n",
      "Epoch 15/120\n",
      "22/22 [==============================] - 0s 917us/step - loss: 0.2784 - binary_accuracy: 0.8779\n",
      "Epoch 16/120\n",
      "22/22 [==============================] - 0s 887us/step - loss: 0.2613 - binary_accuracy: 0.8873\n",
      "Epoch 17/120\n",
      "22/22 [==============================] - 0s 783us/step - loss: 0.2790 - binary_accuracy: 0.8967\n",
      "Epoch 18/120\n",
      "22/22 [==============================] - 0s 850us/step - loss: 0.2910 - binary_accuracy: 0.8638\n",
      "Epoch 19/120\n",
      "22/22 [==============================] - 0s 798us/step - loss: 0.2170 - binary_accuracy: 0.9061\n",
      "Epoch 20/120\n",
      "22/22 [==============================] - 0s 847us/step - loss: 0.2030 - binary_accuracy: 0.9249\n",
      "Epoch 21/120\n",
      "22/22 [==============================] - 0s 878us/step - loss: 0.2464 - binary_accuracy: 0.9108\n",
      "Epoch 22/120\n",
      "22/22 [==============================] - 0s 920us/step - loss: 0.1965 - binary_accuracy: 0.9249\n",
      "Epoch 23/120\n",
      "22/22 [==============================] - 0s 878us/step - loss: 0.2501 - binary_accuracy: 0.8967\n",
      "Epoch 24/120\n",
      "22/22 [==============================] - 0s 986us/step - loss: 0.2417 - binary_accuracy: 0.9108\n",
      "Epoch 25/120\n",
      "22/22 [==============================] - 0s 903us/step - loss: 0.1912 - binary_accuracy: 0.9249\n",
      "Epoch 26/120\n",
      "22/22 [==============================] - 0s 872us/step - loss: 0.1827 - binary_accuracy: 0.9296\n",
      "Epoch 27/120\n",
      "22/22 [==============================] - 0s 864us/step - loss: 0.1797 - binary_accuracy: 0.9225\n",
      "Epoch 28/120\n",
      "22/22 [==============================] - 0s 784us/step - loss: 0.1865 - binary_accuracy: 0.9155\n",
      "Epoch 29/120\n",
      "22/22 [==============================] - 0s 838us/step - loss: 0.1938 - binary_accuracy: 0.9225\n",
      "Epoch 30/120\n",
      "22/22 [==============================] - 0s 864us/step - loss: 0.2155 - binary_accuracy: 0.9131\n",
      "Epoch 31/120\n",
      "22/22 [==============================] - 0s 859us/step - loss: 0.1766 - binary_accuracy: 0.9319\n",
      "Epoch 32/120\n",
      "22/22 [==============================] - 0s 836us/step - loss: 0.1627 - binary_accuracy: 0.9437\n",
      "Epoch 33/120\n",
      "22/22 [==============================] - 0s 889us/step - loss: 0.1574 - binary_accuracy: 0.9319\n",
      "Epoch 34/120\n",
      "22/22 [==============================] - 0s 886us/step - loss: 0.1680 - binary_accuracy: 0.9272\n",
      "Epoch 35/120\n",
      "22/22 [==============================] - 0s 820us/step - loss: 0.1787 - binary_accuracy: 0.9272\n",
      "Epoch 36/120\n",
      "22/22 [==============================] - 0s 997us/step - loss: 0.1681 - binary_accuracy: 0.9319\n",
      "Epoch 37/120\n",
      "22/22 [==============================] - 0s 916us/step - loss: 0.1479 - binary_accuracy: 0.9507\n",
      "Epoch 38/120\n",
      "22/22 [==============================] - 0s 928us/step - loss: 0.1634 - binary_accuracy: 0.9366\n",
      "Epoch 39/120\n",
      "22/22 [==============================] - 0s 889us/step - loss: 0.1604 - binary_accuracy: 0.9296\n",
      "Epoch 40/120\n",
      "22/22 [==============================] - 0s 766us/step - loss: 0.1766 - binary_accuracy: 0.9272\n",
      "Epoch 41/120\n",
      "22/22 [==============================] - 0s 859us/step - loss: 0.2163 - binary_accuracy: 0.8944\n",
      "Epoch 42/120\n",
      "22/22 [==============================] - 0s 897us/step - loss: 0.2085 - binary_accuracy: 0.9202\n",
      "Epoch 43/120\n",
      "22/22 [==============================] - 0s 911us/step - loss: 0.1561 - binary_accuracy: 0.9437\n",
      "Epoch 44/120\n",
      "22/22 [==============================] - 0s 821us/step - loss: 0.1386 - binary_accuracy: 0.9531\n",
      "Epoch 45/120\n",
      "22/22 [==============================] - 0s 859us/step - loss: 0.1470 - binary_accuracy: 0.9437\n",
      "Epoch 46/120\n",
      "22/22 [==============================] - 0s 832us/step - loss: 0.1638 - binary_accuracy: 0.9390\n",
      "Epoch 47/120\n",
      "22/22 [==============================] - 0s 859us/step - loss: 0.1362 - binary_accuracy: 0.9577\n",
      "Epoch 48/120\n",
      "22/22 [==============================] - 0s 845us/step - loss: 0.1541 - binary_accuracy: 0.9460\n",
      "Epoch 49/120\n",
      "22/22 [==============================] - 0s 844us/step - loss: 0.1823 - binary_accuracy: 0.9437\n",
      "Epoch 50/120\n",
      "22/22 [==============================] - 0s 901us/step - loss: 0.1913 - binary_accuracy: 0.9061\n",
      "Epoch 51/120\n",
      "22/22 [==============================] - 0s 892us/step - loss: 0.1452 - binary_accuracy: 0.9460\n",
      "Epoch 52/120\n",
      "22/22 [==============================] - 0s 924us/step - loss: 0.1324 - binary_accuracy: 0.9484\n",
      "Epoch 53/120\n",
      "22/22 [==============================] - 0s 954us/step - loss: 0.1290 - binary_accuracy: 0.9437\n",
      "Epoch 54/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1527 - binary_accuracy: 0.9296\n",
      "Epoch 55/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1518 - binary_accuracy: 0.9390\n",
      "Epoch 56/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1403 - binary_accuracy: 0.9390\n",
      "Epoch 57/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1331 - binary_accuracy: 0.9413\n",
      "Epoch 58/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1564 - binary_accuracy: 0.9249\n",
      "Epoch 59/120\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1879 - binary_accuracy: 0.9249\n",
      "Epoch 60/120\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1307 - binary_accuracy: 0.9507\n",
      "Epoch 61/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1206 - binary_accuracy: 0.9577\n",
      "Epoch 62/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1279 - binary_accuracy: 0.9507\n",
      "Epoch 63/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1403 - binary_accuracy: 0.9319\n",
      "Epoch 64/120\n",
      "22/22 [==============================] - 0s 993us/step - loss: 0.1305 - binary_accuracy: 0.9413\n",
      "Epoch 65/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1577 - binary_accuracy: 0.9343\n",
      "Epoch 66/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1892 - binary_accuracy: 0.9131\n",
      "Epoch 67/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1755 - binary_accuracy: 0.9202\n",
      "Epoch 68/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1400 - binary_accuracy: 0.9437\n",
      "Epoch 69/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1174 - binary_accuracy: 0.9484\n",
      "Epoch 70/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1191 - binary_accuracy: 0.9507\n",
      "Epoch 71/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1343 - binary_accuracy: 0.9531\n",
      "Epoch 72/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1169 - binary_accuracy: 0.9554\n",
      "Epoch 73/120\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1115 - binary_accuracy: 0.9554\n",
      "Epoch 74/120\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1034 - binary_accuracy: 0.9601\n",
      "Epoch 75/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0963 - binary_accuracy: 0.9531\n",
      "Epoch 76/120\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1387 - binary_accuracy: 0.9484\n",
      "Epoch 77/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1371 - binary_accuracy: 0.9390\n",
      "Epoch 78/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1255 - binary_accuracy: 0.9413\n",
      "Epoch 79/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1037 - binary_accuracy: 0.9601\n",
      "Epoch 80/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1529 - binary_accuracy: 0.9319\n",
      "Epoch 81/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1822 - binary_accuracy: 0.9249\n",
      "Epoch 82/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1427 - binary_accuracy: 0.9390\n",
      "Epoch 83/120\n",
      "22/22 [==============================] - 0s 973us/step - loss: 0.1479 - binary_accuracy: 0.9413\n",
      "Epoch 84/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1121 - binary_accuracy: 0.9531\n",
      "Epoch 85/120\n",
      "22/22 [==============================] - 0s 912us/step - loss: 0.1117 - binary_accuracy: 0.9507\n",
      "Epoch 86/120\n",
      "22/22 [==============================] - 0s 923us/step - loss: 0.1061 - binary_accuracy: 0.9554\n",
      "Epoch 87/120\n",
      "22/22 [==============================] - 0s 902us/step - loss: 0.0961 - binary_accuracy: 0.9648\n",
      "Epoch 88/120\n",
      "22/22 [==============================] - 0s 891us/step - loss: 0.1058 - binary_accuracy: 0.9554\n",
      "Epoch 89/120\n",
      "22/22 [==============================] - 0s 925us/step - loss: 0.1183 - binary_accuracy: 0.9413\n",
      "Epoch 90/120\n",
      "22/22 [==============================] - 0s 931us/step - loss: 0.1008 - binary_accuracy: 0.9531\n",
      "Epoch 91/120\n",
      "22/22 [==============================] - 0s 879us/step - loss: 0.1380 - binary_accuracy: 0.9390\n",
      "Epoch 92/120\n",
      "22/22 [==============================] - 0s 908us/step - loss: 0.1290 - binary_accuracy: 0.9343\n",
      "Epoch 93/120\n",
      "22/22 [==============================] - 0s 825us/step - loss: 0.1255 - binary_accuracy: 0.9390\n",
      "Epoch 94/120\n",
      "22/22 [==============================] - 0s 813us/step - loss: 0.1101 - binary_accuracy: 0.9460\n",
      "Epoch 95/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1103 - binary_accuracy: 0.9413\n",
      "Epoch 96/120\n",
      "22/22 [==============================] - 0s 942us/step - loss: 0.0998 - binary_accuracy: 0.9531\n",
      "Epoch 97/120\n",
      "22/22 [==============================] - 0s 880us/step - loss: 0.1115 - binary_accuracy: 0.9484\n",
      "Epoch 98/120\n",
      "22/22 [==============================] - 0s 889us/step - loss: 0.1545 - binary_accuracy: 0.9272\n",
      "Epoch 99/120\n",
      "22/22 [==============================] - 0s 827us/step - loss: 0.1243 - binary_accuracy: 0.9531\n",
      "Epoch 100/120\n",
      "22/22 [==============================] - 0s 862us/step - loss: 0.1429 - binary_accuracy: 0.9319\n",
      "Epoch 101/120\n",
      "22/22 [==============================] - 0s 854us/step - loss: 0.1049 - binary_accuracy: 0.9601\n",
      "Epoch 102/120\n",
      "22/22 [==============================] - 0s 825us/step - loss: 0.1214 - binary_accuracy: 0.9484\n",
      "Epoch 103/120\n",
      "22/22 [==============================] - 0s 860us/step - loss: 0.1232 - binary_accuracy: 0.9437\n",
      "Epoch 104/120\n",
      "22/22 [==============================] - 0s 829us/step - loss: 0.1107 - binary_accuracy: 0.9531\n",
      "Epoch 105/120\n",
      "22/22 [==============================] - 0s 860us/step - loss: 0.0900 - binary_accuracy: 0.9601\n",
      "Epoch 106/120\n",
      "22/22 [==============================] - 0s 813us/step - loss: 0.0861 - binary_accuracy: 0.9601\n",
      "Epoch 107/120\n",
      "22/22 [==============================] - 0s 857us/step - loss: 0.0891 - binary_accuracy: 0.9624\n",
      "Epoch 108/120\n",
      "22/22 [==============================] - 0s 869us/step - loss: 0.0910 - binary_accuracy: 0.9601\n",
      "Epoch 109/120\n",
      "22/22 [==============================] - 0s 867us/step - loss: 0.1235 - binary_accuracy: 0.9390\n",
      "Epoch 110/120\n",
      "22/22 [==============================] - 0s 954us/step - loss: 0.1257 - binary_accuracy: 0.9437\n",
      "Epoch 111/120\n",
      "22/22 [==============================] - 0s 897us/step - loss: 0.1006 - binary_accuracy: 0.9624\n",
      "Epoch 112/120\n",
      "22/22 [==============================] - 0s 865us/step - loss: 0.0956 - binary_accuracy: 0.9484\n",
      "Epoch 113/120\n",
      "22/22 [==============================] - 0s 976us/step - loss: 0.1040 - binary_accuracy: 0.9554\n",
      "Epoch 114/120\n",
      "22/22 [==============================] - 0s 879us/step - loss: 0.1069 - binary_accuracy: 0.9554\n",
      "Epoch 115/120\n",
      "22/22 [==============================] - 0s 926us/step - loss: 0.1055 - binary_accuracy: 0.9460\n",
      "Epoch 116/120\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0965 - binary_accuracy: 0.9577\n",
      "Epoch 117/120\n",
      "22/22 [==============================] - 0s 979us/step - loss: 0.0894 - binary_accuracy: 0.9554\n",
      "Epoch 118/120\n",
      "22/22 [==============================] - 0s 797us/step - loss: 0.0934 - binary_accuracy: 0.9554\n",
      "Epoch 119/120\n",
      "22/22 [==============================] - 0s 797us/step - loss: 0.1093 - binary_accuracy: 0.9507\n",
      "Epoch 120/120\n",
      "22/22 [==============================] - 0s 950us/step - loss: 0.0952 - binary_accuracy: 0.9601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f30682a4860>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(entry_train, class_train, batch_size=20, epochs=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates output predictions for the input samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevision = classifier.predict(entry_test)\n",
    "prevision = (prevision > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]]\n"
     ]
    }
   ],
   "source": [
    "print(prevision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 776us/step - loss: 0.4332 - binary_accuracy: 0.9091\n"
     ]
    }
   ],
   "source": [
    "result = classifier.evaluate(entry_test, class_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4332408905029297, 0.9090909361839294]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_value = np.array([[\n",
    "    15.80, 8.34, 118, 900, 0.10, 0.26, 0.8, 0.134, 0.178, 0.20, 0.5, 1098, 0.87, 4500, 145.2, 0.005, 0.04, 0.05, 0.015,\n",
    "    0.03, 0.007, 23.15, 16.64, 178.15, 2018, 0.14, 0.185, 0.84, 158, 0.363\n",
    "]])\n",
    "\n",
    "prevision = classifier.predict(test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "print(prevision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save neural network and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save neural network\n",
    "classifier_json = classifier.to_json()\n",
    "\n",
    "with open('network/breast_classifier.json', 'w') as json_file:\n",
    "    json_file.write(classifier_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "classifier.save_weights('model/breast_classifier.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
